---
TITLE: "Breast Cancer Prediction from Data"


#### INTRODUCTION

The Breast Cancer (Wisconsin) Diagnosis dataset contains the diagnosis and a set of 32 features describing the characteristics of the 
cell nuclei present in the digitized image of a fine needle aspirate (FNA) of a breast mass.

Ten real-valued features are computed for each cell nucleus:  

+ radius (mean of distances from center to points on the perimeter);  
+ texture (standard deviation of gray-scale values);  
+ perimeter;  
+ area;  
+ smoothness (local variation in radius lengths);  
+ compactness (perimeter^2 / area - 1.0);  
+ concavity (severity of concave portions of the contour);  
+ concave points (number of concave portions of the contour);  
+ symmetry;  
+ fractal dimension ("coastline approximation" - 1).

The mean, standard error (SE) and "worst" or largest (mean of the three largest values) of these features were computed for each 
image, resulting in 30 features.

Purpose is to analyze the features to understand the predictive value for  breast cancer diagnosis.
Approach is to create models using different algorithms and use the models to predict the diagnosis.

###############################################################################################################################################
# Installing required Packages

install.packages("Rtsne")
install.packages("corrplot")
install.packages("extracat")
install.packages("pROC")
install.packages("gbm")
install.packages("xgboost")
install.packages("C50")
install.packages("vcd")
install.packages("extracat")
install.packages("knitr")
install.packages("caret")
install.packages("randomForest")
install.packages("readr")
install.packages("clusterGeneration")
install.packages("NeuralNetTools")
install.packages("devtools")
################################################################################################################################################
---

# Importing Libraries
```{r setup, include=FALSE}
library(Matrix)
library(randomForest) # For Random Forest Model
library(Rtsne) # For Stochastic Neighbor Embedding (t-SNE)
library(gridExtra)
library(corrplot)
library(dplyr)
library(extracat)
library(pROC)
library(gbm)  # For Gradient Boosting Machine
library(xgboost) # For Extreme Gradient Boost
library(ggplot2)
library(plyr)
library(scales)
library(grid)
library(caret)  # For pca and data partition
library(nnet)   # For neural network modeling
library(C50)    # For decision tree modeling
library(readr)  # read_csv() is fast read facility 
library(vcd)    # For association plots
library(clusterGeneration)
library(devtools)
library(NeuralNetTools) # For Neural Networks
```

# Reading the Source data:
```{r input_data}
data <- read.csv("Resources/data.csv")
data
```

# Explore the features:

Summary of the data
```{r data_summary}
summary(data)

```


The field `diagnosis` has either `B` (Benign) or `M` (Malignant) value. Display Counts in each category.
```{r diagnosis_percent}
diagnostic <- plyr::count(data$diagnosis)
print(sprintf("Malignant: %d | Benign: %d",diagnostic$freq[2],diagnostic$freq[1]))
print(sprintf("Percent of malignant tumor: %.1f%%",round(diagnostic$freq[2]/nrow(data)*100,1)))
```

The dataset does not represent a typical normal distribution in medicine. Usually there will be a large number of cases that represent Benign Tumors vs. a small number of Malignant tumors. 

## Feature plots to analyze features with higher predictive value in order to create a model 

Eliminate `id` and `X` columns populated with only `NA` values.
Use the `diagnostic` feature as the group factor.
```{r features}
newColumns = c(
  "fractal_dimension_mean",  "fractal_dimension_se", "fractal_dimension_worst",
  "symmetry_mean", "symmetry_se", "symmetry_worst",
  "concave.points_mean", "concave.points_se", "concave.points_worst",
  "concavity_mean","concavity_se", "concavity_worst",
  "compactness_mean", "compactness_se", "compactness_worst",
  "smoothness_mean", "smoothness_se", "smoothness_worst",
  "area_mean", "area_se", "area_worst",
  "perimeter_mean",  "perimeter_se", "perimeter_worst",
  "texture_mean" , "texture_se", "texture_worst",
  "radius_mean", "radius_se", "radius_worst"
)

bc.data = (data[,newColumns])
bc.diag = data[,2]
```


################################### Feature density
For the feature plot, the density plot represents both the values density and the degree of separation of the two sets of categories, on each feature direction.
```{r fig.width=8, fig.height=16, feature_plot_density}
density_scales <- list(x=list(relation="free"),y=list(relation="free"), cex=0.6)
featurePlot(x=bc.data, y=bc.diag, plot="density",scales=density_scales,
            layout = c(3,10), auto.key = list(columns = 2), pch = "|")
```
Conclusion: There is no perfect separation between the features. 
Fair separation can be seen for `concave.points_worst`, `concavity_worst`, `perimeter_worst`, `area_mean`, `perimeter_mean`. 

##################################### Pearson correlation

Correlation between the features using `cor` function for `Pearson` correlation.
The solution to correlated columns is one of the correlated columns should be removed for the model.

```{r fig.width=8, fig.height=8, correlation}
nc=ncol(data)
df <- data[,3:nc-1]
df$diagnosis <- as.integer(factor(df$diagnosis))-1
correlations <- cor(df,method="pearson")
corrplot(correlations, number.cex = .9, method = "color", 
         hclust.method = "ward", order = "FPC",
         type = "full", tl.cex=0.8,tl.col = "black")

```
The highest correlations are between the pairs:  

* `perimeter_mean` and `radius_worst`;  
* `area_worst` and `radius_worst`;  
* `perimeter_worst` and `radius_worst`, `perimeter_mean`, `area_worst`, `area_mean`, `radius_mean`;  
* `texture_mean` and `texture_worst`; 

Pairs inverse correlated are:
* `radius_mean` and `fractal_dimension_mean`; 
* `area_worst` and `fractal_dimension_mean`; 

Pairs very lowly correlated are:
* `area_se` and `fractal_dimension_worst`; 
* `radius_se` and `fractal_dimension_worst`; 
* `texture_mean` and `smoothness_mean`; 
* `perimeter_worst` and `fractal_dimension_se`; 


##### t-SNE transform
PCA is a linear algorithm but t-SNE is a non-linear dimensionality reduction algorithm. It finds patterns in the data by identifying 
observed clusters based on similarity of data points with multiple features. It can be used for data exploration and visualization.
```{r t-sne}
library(Rtsne)
colors = rainbow(length(unique(bc.diag)))
names(colors) = unique(bc.diag)
tsne <- Rtsne(bc.data, dims = 2, perplexity=10, verbose=TRUE, max_iter = 500)
plot(tsne$Y, t='n', main="t-Distributed Stochastic Neighbor Embedding (t-SNE)",
     xlab="t-SNE 1st dimm.", ylab="t-SNE 2nd dimm.")
text(tsne$Y, labels=bc.diag, cex=0.5, col=colors[bc.diag])

```



# Predictive models: `RandomForest` (`RF`), `Gradient Boosting Machine` (`GBM`), & `XGBoost`.
```{r model}
df <- data[,2:32]
df$diagnosis = as.integer(factor(df$diagnosis))-1
nrows <- nrow(df)
set.seed(314)
indexT <- sample(1:nrow(df), 0.7 * nrows)
#separate train and validation set
trainset = df[indexT,] ###--80%
testset =   df[-indexT,]###--20%
n <- names(trainset)
```


## Random Forest using all features
Set the number of trees to 500. For the rest of the parameters with default settings.
```{r random_forest_model, message=FALSE, echo=FALSE}
rf.form <- as.formula(paste("diagnosis ~", paste(n[!n %in% "diagnosis"], collapse = " + ")))
trainset.rf <- randomForest(rf.form,trainset,ntree=500,importance=T)
```
Error evolution vs. number of trees:  We can see that, up to about 300 trees, the error stabilizes which indicates that the obtained random forest has reached its optimal classification error.

```{r random_forest_model_mse_error}
plot(trainset.rf, main="Random Forest: MSE error vs. no of trees")
```

Visualize the variable importance with two methods, **IncNodePurity** and **%IncMSE**:

**IncNodePurity** relates to the loss function, is the total decrease in node impurities, measured by the Gini Index from splitting on the variable, averaged over all trees.

**%IncMSE** the most robust and informative measure, is the increase in mse of predictions as a result of variable **j** being permuted(values randomly shuffled).

```{r fig.width=9, fig.height=3, variable_importance}
varimp <- data.frame(trainset.rf$importance)
  vi1 <- ggplot(varimp, aes(x=reorder(rownames(varimp),IncNodePurity), y=IncNodePurity)) +
  geom_bar(stat="identity", fill="tomato", colour="black") +
  coord_flip() + theme_bw(base_size = 8) +
  labs(title="Prediction using RandomForest with 500 trees", subtitle="Variable importance (IncNodePurity)", x="Variable", y="Variable importance (IncNodePurity)")
  vi2 <- ggplot(varimp, aes(x=reorder(rownames(varimp),X.IncMSE), y=X.IncMSE)) +
  geom_bar(stat="identity", fill="blue", colour="black") +
  coord_flip() + theme_bw(base_size = 8) +
  labs(title="Prediction using RandomForest with 500 trees", subtitle="Variable importance (%IncMSE)", x="Variable", y="Variable importance (%IncMSE)")
grid.arrange(vi1, vi2, ncol=2)
```

Observations are  `perimeter_worst`, `area_worst`, `concave.points_worst`, `radius_worst`, `concavity_mean`, `concavity_worst`, `area_se`, `concave.points_mean` are the most important features. 


### RANDOM FOREST 
Using the Random Forest model for **test** data.
```{r random_forest_prediction}
testset$predicted <- round(predict(trainset.rf ,testset),0)
```

Visualize the confusion matrix for accuracy.
```{r fig.width=4, fig.height=4, show_confusion_matrix}
plotConfusionMatrix <- function(testset, sSubtitle) {
    tst <- data.frame(testset$predicted, testset$diagnosis)
    opts <- c("Predicted", "True")
    names(tst) <- opts
    cf <- plyr::count(tst)
    cf[opts][cf[opts]==0] <- "Benign"
    cf[opts][cf[opts]==1] <- "Malignant"
    ggplot(data =  cf, mapping = aes(x = True, y = Predicted)) +
      labs(title = "Confusion matrix", subtitle = sSubtitle) +
      geom_tile(aes(fill = freq), colour = "grey") +
      geom_text(aes(label = sprintf("%1.0f", freq)), vjust = 1) +
      scale_fill_gradient(low = "gold", high = "tomato") +
      theme_bw() + theme(legend.position = "none")
}
plotConfusionMatrix(testset,"Prediction using RandomForest with 500 trees")
```

AUC Calculation for the prediction:
```{r auc}
print(sprintf("Area under curve (AUC) : %.3f",auc(testset$diagnosis, testset$predicted)))
```

### Model with reduced number of features
Run Random Forest model with a reduced number of features to `22` out of `33` with the highest importance, according to *%IncMSE* criteria.
```{r model_prediction_random_forest_reduced_features_set}
features_list = c("perimeter_worst", "area_worst", "concave.points_worst", "radius_worst", 
                  "concavity_mean", "concavity_worst","area_se", "concave.points_mean",
                  "texture_worst", "area_mean", "texture_mean", "area_mean", 
                  "radius_mean", "radius_se", "perimeter_mean", "perimeter_se",
                  "compactness_worst", "smoothness_worst", "concavity_se",
                  "fractal_dimension_worst", "symmetry_worst",  "diagnosis")
#define train and validation set
trainset_fl = trainset[,features_list]
testset_fl =   testset[,features_list]
#training
n <- names(trainset_fl)
rf.form <- as.formula(paste("diagnosis ~", paste(n[!n %in% "diagnosis"], collapse = " + ")))
trainset.rf <- randomForest(rf.form,trainset_fl,ntree=500,importance=T)
#prediction
testset_fl$predicted <- round(predict(trainset.rf ,testset_fl),0)
```
Predictions with the Confusion Matrix and AUC value:
```{r fig.width=4, fig.height=4, confusion_matric_auc_random_forest_reduced_features_set}
plotConfusionMatrix(testset_fl,"Prediction using RandomForest with reduced features")
print(sprintf("Area under curve (AUC) : %.3f",auc(testset_fl$diagnosis, testset_fl$predicted)))
```

Assuming detection of a malignant tumor as a `positive`, the result of using reduced features set, decreased the true positive (**TP**) number and increased false negative (**FN**) number, while true negative and false positive numbers are unchanged. 

The AUC decreased as well to `0.940` due to decrease of sensitivity.

################### Gradient Boosting Machine (GBM)
GBM model with cross validation with 5 folds.
```{r gbm_model}
n<-names(trainset)
gbm.form <- as.formula(paste("diagnosis ~", paste(n[!n %in% "diagnosis"], collapse = " + ")))
gbmCV = gbm(formula = gbm.form,
               distribution = "bernoulli",
               data = trainset,
               n.trees = 500,
               shrinkage = .1,
               n.minobsinnode = 15,
               cv.folds = 5,
               n.cores = 1)
```

Using `gbm.perf` function: returns the optimal number of trees for prediction.
```{r gbm_best_nodes_number, echo=FALSE, message=FALSE}
optimalTreeNumberPredictionCV = gbm.perf(gbmCV)
```
```{r gbm_model_t}
gbmTest = predict(object = gbmCV,
                           newdata = testset,
                           n.trees = optimalTreeNumberPredictionCV,
                           type = "response")
testset$predicted <- round(gbmTest,0)
```


```{r fig.width=4, fig.height=4, show_confusion_matrix_gbm}
plotConfusionMatrix(testset,sprintf("Prediction using GBM (%d trees)",optimalTreeNumberPredictionCV))
```
AUC calculation for the prediction:

```{r auc_gbm}
print(sprintf("Area under curve (AUC) : %.3f",auc(testset$diagnosis, testset$predicted)))
```

## EXTREME GRADIENT BOOST (XGBoost): Create `xgb.DMatrix` objects for each train & test set.
```{r xgboost_matrix_data}
dMtrain <- xgb.DMatrix(as.matrix(trainset), label = trainset$diagnosis)
dMtest <- xgb.DMatrix(as.matrix(testset), label = testset$diagnosis)

```

```{r}
dMtrain
```
```{r}
dMtest
```

Use a binary logistic  objective function.  The evaluation metric will be AUC (Area under curve). 
```{r xgboost_model_params}
params <- list(
  "objective"           = "binary:logistic",
  "eval_metric"         = "auc",
  "eta"                 = 0.012,
  "subsample"           = 0.8,
  "max_depth"           = 8,
  "colsample_bytree"    =0.9,
  "min_child_weight"    = 5
)
```


Train the model using cross validation with 5 folds. We are using a number of rounds equal with 5000, with early stopping criteria for 100 steps. We are also setting the frequency of printing partial results every 100 steps.
```{r xgboost_cv}
nRounds <- 5000
earlyStoppingRound <- 100
printEveryN = 100
model_xgb.cv <- xgb.cv(params=params,
                      data = dMtrain, 
                      maximize = TRUE,
                      nfold = 5,
                      nrounds = nRounds,
                      nthread = 1,
                      early_stopping_round=earlyStoppingRound,
                      print_every_n=printEveryN)
d <- model_xgb.cv$evaluation_log
n <- nrow(d)
v <- model_xgb.cv$best_iteration
df <- data.frame(x=rep(d$iter, 2), val=c(d$train_auc_mean, d$test_auc_mean), 
                   set=rep(c("train", "test"), each=n))
ggplot(data = df, aes(x=x, y=val)) + 
  geom_line(aes(colour=set)) + 
  geom_vline(xintercept=v) + 
  theme_bw() +
  labs(title="AUC values for XGBoost with cross-validation", x="Iteration", y="AUC values (train, test)")
```


The `AUC` for train and test set obtained using the training with cross validation have close values. Both are above 0.99.


```{r xgboost_predict}
model_xgb <- xgboost(params=params,
                      data = dMtrain, 
                      maximize = TRUE,
                      nrounds = nRounds,
                      nthread = 1,
                      early_stopping_round=earlyStoppingRound,
                      print_every_n=printEveryN)
d <- model_xgb$evaluation_log
n <- nrow(d)
df <- data.frame(x=rep(d$iter), val=d$train_auc)
ggplot(data = df, aes(x=x, y=val)) + 
  geom_line() + 
  theme_bw() +
  labs(title="AUC values for XGBoost", x="Iteration", y="AUC values (train)")
```

Predict the test data:
```{r xgboost_prediction}
#testset$predicted <- round(predict(object = model_xgb.cv ,newdata = dMtest),0)
```

Visualize the confusion matrix for accuracy:
                           n.trees = optimalTreeNumberPredictionCV,
                           type = "response"

```{r fig.width=4, fig.height=4, show_confusion_matrix_xgboost}
plotConfusionMatrix(testset,"Prediction using XGBoost")
```

 AUC calculation for the prediction:

```{r auc_xgboost}
print(sprintf("Area under curve (AUC) : %.3f",auc(testset$diagnosis, testset$predicted)))
```


#####################################################################################################################################################
# Conclusions:

The features  `concave.ponts_worst`, `concavity_mean`, `concavity_worst`, `perimeter_worst`, `area_worst` have more predictive value for the diagnosis.

The observations were confirmed by the PCA analysis, showing that the same features are aligned to main principal component or have larger 
dimmension in the PCA plan.


Three models `Random Forest`, `Gradient Boosting Machine (GBM)`,  and `XGBoost` were used to predict good accuracy (big ROC AUC value) 
the malignant and benign tumors


Using cross validation, the best prediction model was `Gradient Boosting Machine(GBM)` .

######################################################################################################################################################

###############  NEURAL NETWORK MODEL

```{r input_data}
bc_data <- read.csv("Resources/data.csv")
```

```{r}
bcIndex<-createDataPartition(bc_data$diagnosis,
                             p = 0.8,
                             list=F)   # 80:20 data partition
train<-bc_data[bcIndex,]                                         # 80% train data
valid<-bc_data[-bcIndex,]                                        # 20% validation data
```

```{r}
abc <- bc_data[-c(1,33)]
```

```{r}
# Neural network Model
model_nnet<-nnet(diagnosis ~. ,
                 data= abc,
                 size=10
                 )
result1<-predict(model_nnet,
                 valid[,-2],
                 type = c("class")
     
                             ) # Prediction on validation set
```


```{r}
(accuracy<-sum(result1 == valid$diagnosis)/nrow(valid)) 
```

Plot the NEURAL-NETWORK
```{r}
par(mar = numeric(4), family = 'serif',size=c(9,11,8))
plotnet(model_nnet)
```

Conduct a sensitivity analysis of model responses in a neural network to input variables using Lek's profile method
```{r}
lekprofile(model_nnet)
```
